# -*- coding: utf-8 -*-
"""FEATURE EXTRACTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wupMVzdhR9bbvjmQxqgB1bwAv1Zq5m7U
"""

import pandas as pd

df_clean = pd.read_csv('clean.csv')
df = pd.concat([df_clean, df_clean], ignore_index=True)

df.head()

df.shape

df.Sentiment.value_counts()

import nltk

nltk.download('punkt_tab')

from nltk.tokenize import sent_tokenize

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = sent_tokenize(text)
text

from nltk.tokenize import word_tokenize

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = word_tokenize(text)
text

import re

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = re.sub(r'[^\w\s]', '', text)
text

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = re.sub(r'\d+', '', text)
text

stopwords = ["ini", "oleh", "yang", "sudah", "di", "cukup", "jadilah", "dari", "nya", "i"]
text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"

words = text.split(' ')
for word in words:
  if word not in stopwords:
    print(word)

stopwords = ["ini", "oleh", "yang", "sudah", "di", "cukup", "jadilah", "dari", "nya", "i"]
text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"

words = text.split(' ')
for word in words:
  if word not in stopwords:
    print(word)

data_preprocessed = df.Text_Bersih.tolist()

data_preprocessed

import numpy as np

data_preprocessed = [x for x in data_preprocessed if x is not np.nan and x is not None and (isinstance(x, str) or isinstance(x, bytes) or (isinstance(x, float) and not pd.isna(x)))]

from sklearn.feature_extraction.text import CountVectorizer

count_vect = CountVectorizer()
count_vect.fit(data_preprocessed)

count_vect.vocabulary_

X = count_vect.transform(data_preprocessed)

X.shape

print (X)

print ("Feature Extraction selesai")

import pickle
with open("feature.p", "wb") as file:
  pickle.dump(count_vect, file)

from sklearn.model_selection import train_test_split
classes = df.Sentiment

classes

classes = df.loc[df['Text_Bersih'].notna(), 'Sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.2)

# Create DataFrames for train and test data
train_data = pd.DataFrame(X_train.toarray())  # Convert X_train to a DataFrame
train_data['Sentiment'] = y_train  # Add the target variable

test_data = pd.DataFrame(X_test.toarray())  # Convert X_test to a DataFrame
test_data['Sentiment'] = y_test   # Add the target variable

train_data.to_csv('train_data.csv', index=False)
test_data.to_csv('test_data.csv', index=False)

print("Train and Test data have been exported successfully!")

