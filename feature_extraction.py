# -*- coding: utf-8 -*-
"""FEATURE EXTRACTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wupMVzdhR9bbvjmQxqgB1bwAv1Zq5m7U
"""

import pandas as pd

df_clean = pd.read_csv('clean.csv')

df_clean.head()

df_clean.shape

df_clean.Sentiment.value_counts()

print(df_clean.isnull().sum())

print(df_clean.isnull().any().any())

df_cleaned = df_clean.dropna()

print (df_cleaned)

df_cleaned.isnull().sum()

import nltk

nltk.download('punkt_tab')

from nltk.tokenize import sent_tokenize

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = sent_tokenize(text)
text

from nltk.tokenize import word_tokenize

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = word_tokenize(text)
text

import re

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = re.sub(r'[^\w\s]', '', text)
text

text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"
text = re.sub(r'\d+', '', text)
text

stopwords = ["ini", "oleh", "yang", "sudah", "di", "cukup", "jadilah", "dari", "nya"]
text = "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung tahu berkualitas dipadu keahlian memasak dipadu kretivitas jadilah warung yang menyajikan menu utama berbahan tahu ditambah menu umum lain sepe i ayam semuanya selera indonesia harga cukup terjangkau jangan melewati tahu bletoka nya tidak kalah dengan yang asli dari tegal"

words = text.split(' ')
for word in words:
  if word not in stopwords:
    print(word)

empty_rows = df_cleaned['Sentiment'].str.strip().eq('')
print (empty_rows)
print ({empty_rows.sum()})

data_preprocessed = df_cleaned.Text_Bersih.tolist()

data_preprocessed

data_preprocessed_series = pd.Series(data_preprocessed)

null_count = data_preprocessed_series.isnull().sum()

print(null_count)

import numpy as np

data_preprocessed = [x for x in data_preprocessed if x is not np.nan and x is not None and (isinstance(x, str) or isinstance(x, bytes) or (isinstance(x, float) and not pd.isna(x)))]

data_preprocessed_series = pd.Series(data_preprocessed)
null_count = data_preprocessed_series.isnull().sum()
print(null_count)

from sklearn.feature_extraction.text import CountVectorizer

count_vect = CountVectorizer()
count_vect.fit(data_preprocessed)

count_vect.vocabulary_

from sklearn.model_selection import train_test_split
classes = df_cleaned.Sentiment
classes

classes.shape[0]

num_nan = classes.isnull().sum()
print( num_nan)

X = count_vect.transform(data_preprocessed)

X.shape

print ("Feature Extraction selesai")

import pickle
with open("feature.p", "wb") as file:
  pickle.dump(count_vect, file)

X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.2)

# Create DataFrames for train and test data
train_data = pd.DataFrame(X_train.toarray(), index=y_train.index)
train_data['Sentiment'] = y_train

test_data = pd.DataFrame(X_test.toarray(), index=y_test.index)
test_data['Sentiment'] = y_test

print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("train_data shape:", train_data.shape)

y_train = y_train.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)

X_train_dense = X_train.toarray()
X_test_dense = X_test.toarray()

train_data = pd.DataFrame(X_train_dense)
train_data['Sentiment'] = y_train.values

test_data = pd.DataFrame(X_test_dense)
test_data['Sentiment'] = y_test.values

train_data.to_csv('train_data.csv', index=False)
test_data.to_csv('test_data.csv', index=False)

print("Train and Test data have been exported successfully!")

df_train = pd.read_csv('train_data.csv')

df_train.head()

df_train.shape

df_test = pd.read_csv('test_data.csv')

df_test.head()

df_test.shape

print(df_train.isnull().sum())

print(df_test.isnull().sum())

vector_columns = df_train.columns.difference(['Sentiment']).tolist()

mean_values = df_train[vector_columns].mean(axis=1)
max_values = df_train[vector_columns].max(axis=1)
min_values = df_train[vector_columns].min(axis=1)

print (mean_values)

print (min_values)

print(max_values)

